# 2-1

## a

- `n/k` sublists of length `k`
- worst case: `Θ(n²)`
- per sublist: `Θ(k²)` (worst case)
- for `n/k` sublists: `Θ(n/k * k²) = Θ(nk)` q.e.d.

## b

- `n` sublists of size `1`
- `n/k` sublists of size `k`
- `n` elements -> `n` sublists of size `1`
- depth of the tree: `lg(n)+1`, i.e. every element is merged in `lg(n)` times
- `n/k` sublists -> `n` elements, each merged only `lg(n/k)` times (shallower tree)

## c

TODO

## d

Run both Insertion Sort and Merge Sort for inputs of size `n=1..` to figure out
at which point Merge Sort becomes faster than insertion sort. Then use this `n`
as the length for sublists.

# 2-2

## a

`A'` must also contain all the elements of `A`.

## b

The inner loop moves the smallest element of the subsequence `A[i+1:n]` to the
position `A[i]`.

- Initialization: The loop always starts at the rightmost element `n`.
- Maintenance: In every step, the smaller element of the adjacent pair is moved
  one step to the left.
- Termination: The loop ends, once the smallest element of the subsequence
  `A[i+1:n]` has been moved to position `A[i]`.

## c

The outer loop starts with an unsorted array and turns it into a sorted array by
starting at the leftmost position, increasing the size of the sorted part in
every iteration, thereby decreasing the size of the unsorted part.

- Initialization: The loop starts at the first element.
- Maintenance: Since the inner loop moves the smallest element of the
  subsequence `A[i+1:n]` to position `A[i]`, the subsequence `A[1:i]` is sorted
  after every iteration of the outer loop.
- Termination: The outer loop ends when the `n-1` smallest elements of `A` have
  been moved into the sorted part, thus only leaving the biggest element at
  position `n`.

## d

The outer loop is performed `n-1` times, i.e. `Θ(n)`. The inner loop, started
`n-1` times, performes `n-i+1` iterations; i.e. `(n-1)/2` times on average,
which is `Θ(n)` again. Thus, Bubble Sort runs in `Θ(n²)` (worst time, best
time).

# 2-3

## a

`Θ(n)`

## b

    p = 0
    for k = 0 to n
        p = p + A[k] * x^k
    return p

The algorithms also runs in `Θ(n)`, but requires explicit exponentiation in each
step, which will result in a worse run time in practice, compared to the Horner
algorithm.

## c

Consider `i=n-1`, i.e. the invariant for the last iteration:

    p = sum from k=0 up to n-(n-1+1) of A[k+n-1+1]*x^k
    p = sum from k=0 up to n-n of A[k+n]*x^k
    p = sum from k=0 up to 0 of A[k]*x^k
    p = 0

# 2-4

## a

    (2,1)
    (3,1)
    (8,6)
    (8,1)
    (6,1)

## b

An array sorted in reverse order (i.e. descendingly sorted) has the most
inversions, which can be computed as the sum from `i=1` up to `n` of `i-1`. For
example, the array `[5, 4, 3, 2, 1]` of size `n=5` has `10` inversions.

## c

Each inversion requires an insertion to be performed, and each insertion
requires one or many shift operations. The more inversions there are, the more
insertions and shifts have to be performed, slowing down the process.

## d

    s = 0
    for i = 1 to n
        for j = i + 1 to n
            if A[i] > A[j]
                s += 1
    return s

